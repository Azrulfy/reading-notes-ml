# Title: Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks

# Author: Finn et al (2017)

#### General Content: Introduce a general multi-task initialization procedure which tunes the parameters to be sensitive to changes in the task. It alters the gradient descent update according to a meta objective which allows the model to adapt to new task in very few GD steps.


#### Keypoints:

* Meta-Learning challenge: Agent must integrate prior knowledge with small amount of new info, while avoiding overfittingof new data (catastrophic forgetting).
    * Previous approaches:
        * Learn an update function/learning rule (e.g. a separate network - recurrent/Siamese)
        * Learn good representations suitable for many tasks
    * This approach - Explicit: No additional parameters/architecture constraint
        * Dynamical systems PoV: Maximize the sensitivity of the loss functions of new tasks with respect to the params
    * Test Error on new task provides training error for the meta-learner

* Formulation: Distribution of tasks over which we want model to adapt. Improve model by considering test error change wrt params
    * Learn model such that GD-based learning can make rapid progress on new task without overfitting
    * Assumptions: Parametric model with loss that is smooth enough in params that GD methods can be applied

* Algo:
    - Init params randomly
    - While true
        * Sample batch of tasks
        * For all tasks:
            - Evaluate the task-specific loss fct gradient wrt K examples (K-shot)
            - Compute single step basic GD update of params (don't overwrite just store!)
        * Update the parameters according to the gradient of the sum of the task specific loss functions evaluated at the single-step updates computed in the loop! (gradient of gradient!)

* Derive simple setting for regression, classification and RL objectives:
    * For RL: expected reward usually not differentiable (unknown dynamics) - use PG methods to estimate both model gradient updates and the meta-optimization - Additional on-policy rollouts required!

* Related work comparison:
    * Uses same GD update for both learner as well as meta-update
    * Methods explicitly trains the params for sensitivity on a given task-distribution, allowing for extremely efficient adaptation!

* Amazing writing style! In beginning of experiments state what you want to test/explore with the experiments!

* Meta-Learning/Few-shot datasets: Omniglot and MiniImagenet

* Experiments: First order approx of MAML - show that performance is nearly same without full second derivative! Most improvements from gradients of objective at post-update param values rather than from differentiation through the gradient!

#### Questions:

* Is it possible to switch back and forth between different tasks? Or is the architecture just tuned for a single adaptation and then params are in part of space where they are no longer sensitive to task changes?
